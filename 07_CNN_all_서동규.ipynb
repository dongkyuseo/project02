{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCi1GYuoog8u"
      },
      "source": [
        "# 1. 메모리 변수 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5B01MMNdof5j"
      },
      "outputs": [],
      "source": [
        "# 메모리 변수 모두 제거\n",
        "all = [var for var in globals() if var[0] != '_']\n",
        "for var in all:\n",
        "    del globals()[var]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRYA8OesohYY"
      },
      "source": [
        "# 2. 사용 패키지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JxtsE-O4ohue"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "������ ��θ� ã�� �� �����ϴ�.\n",
            "������ ��θ� ã�� �� �����ϴ�.\n",
            "������ ��θ� ã�� �� �����ϴ�.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "!apt-get install -y fonts-nanum > /dev/null\n",
        "!fc-cache -fv > /dev/null\n",
        "!rm -rf ~/.cache/matplotlib > /dev/null\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "plt.rc('font', family = 'NanumBarunGothic')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-8ebJeKTyR7R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-QNKJAomGh"
      },
      "source": [
        "# 3. 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhXM1N3uonwg",
        "outputId": "39418dc6-3e14-48a0-91e0-08949f3866cb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQr1oPi3op4T",
        "outputId": "da68077a-c0b4-44a9-d44e-15832f5ac177"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/data/project02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFPesqGm3som",
        "outputId": "65e1de54-dbbd-418b-ebf4-a373ab149e0e"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d3V-uUhyXaI",
        "outputId": "362b0d58-ffc4-4a1f-afc4-09d45c9556ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['X', 'Y']\n"
          ]
        }
      ],
      "source": [
        "PATH = 'data/'\n",
        "train_npz = np.load(PATH + 'train_plant_all.npz')\n",
        "# test_npz = np.load(PATH + 'val_plant_all.npz')\n",
        "print(list(train_npz))\n",
        "# print(list(test_npz))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QL5wfzsOWmX8"
      },
      "outputs": [],
      "source": [
        "X_train = train_npz['X']\n",
        "#X_val = \n",
        "y_train = train_npz['Y']\n",
        "#y_val = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 10.5 GiB for an array with shape (14439, 255, 255, 3) and data type float32",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-3c792e2b0f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 10.5 GiB for an array with shape (14439, 255, 255, 3) and data type float32"
          ]
        }
      ],
      "source": [
        "X_train.astype('float32')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = y_train.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r2GPQxsNoSYy"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 14.7 GiB for an array with shape (10107, 255, 255, 3) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-7-29b917cde726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m X_train, X_val, y_train, y_val = train_test_split(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2021\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2197\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2199\u001b[1;33m     return list(chain.from_iterable((_safe_indexing(a, train),\n\u001b[0m\u001b[0;32m   2200\u001b[0m                                      _safe_indexing(a, test)) for a in arrays))\n\u001b[0;32m   2201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2197\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2199\u001b[1;33m     return list(chain.from_iterable((_safe_indexing(a, train),\n\u001b[0m\u001b[0;32m   2200\u001b[0m                                      _safe_indexing(a, test)) for a in arrays))\n\u001b[0;32m   2201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.7 GiB for an array with shape (10107, 255, 255, 3) and data type float64"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size = 0.3, random_state = 2021\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH43p_C9oX9e"
      },
      "outputs": [],
      "source": [
        "print(np.shape(X_train), len(y_train))\n",
        "print(np.shape(X_val), len(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Im0JJLooZh5"
      },
      "outputs": [],
      "source": [
        "# y데이터의 분할은 편향없이 잘 되었는가 확인작업\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "unique_yt = dict(zip(unique, counts))\n",
        "unique_yt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gT7bCY7ocGb"
      },
      "outputs": [],
      "source": [
        "# y데이터의 분할은 편향없이 잘 되었는가 확인작업\n",
        "\n",
        "unique, counts = np.unique(y_val, return_counts=True)\n",
        "\n",
        "unique_yv = dict(zip(unique, counts))\n",
        "unique_yv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X28vnDBi6clp"
      },
      "source": [
        "# 5. CNN\n",
        "- 컨볼루션 신경망\n",
        "- 컴퓨터 비전 (Computer Vision) 에서 사용\n",
        "- 텍스트, 시계열 데이터 등에서도 성능 좋음\n",
        "- 오버피팅 회피\n",
        "    - 규제화 함수\n",
        "        - 가중치 감쇠 (Weight Decay)\n",
        "        - 모델 복잡도 제한\n",
        "        - L1, L2 노름, 엘라스틱 넷 (Elastic Net)\n",
        "        - 기능에 맞춰 가중치 합 구해 손실 함수에 더함\n",
        "        - tensorflow.keras.regularizers.l1(l = 0.01) : 가중치 절대값 합 (릿지)\n",
        "        - tensorflow.keras.regularizers.l2(l = 0.01) : 가중치 제곱값 합 (라쏘)\n",
        "        - tensorflow.keras.regularizers.l1_l2(l1 = 0.01, l2 = 0.01) : 가중치 절대값 합 (릿지) + 가중치 제곱값 합 (라쏘) = (엘라스틱 넷)\n",
        "    - 드롭 아웃\n",
        "        - 학습 진행 중 신경망 일부 유닛 제외\n",
        "        - 테스트 중 작동 하지 않고 모든 유닛 활성화\n",
        "        - 출력을 드롭 아웃 비율만큼 제외\n",
        "        - 드롭 아웃 비율 0.2 ~ 0.5\n",
        "    - 배치 정규화\n",
        "        - 드롭 아웃과 비교\n",
        "        - 내부 공선성 (Internal Covariance Shift) 해결 방법\n",
        "        - 출력값 범위 제한 -> 불확실성 감소 목적\n",
        "        - 그래디언트 손실, 폭주 없이 높은 학습률 사용 가능\n",
        "        - 자체적 규제화 효과 포함\n",
        "        - Dense or Conv2D -> BatchNormalization() -> Activation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NG6Tezt6xg0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
        "from tensorflow.keras.layers import Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "model = Sequential()\n",
        "# (255, 255, 3)\n",
        "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same',\n",
        "                 input_shape = (255, 255, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same',\n",
        "                 kernel_regularizer = l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size = (2, 2), strides = 2, padding = 'same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same',\n",
        "                 kernel_regularizer = l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same',\n",
        "                 kernel_regularizer = l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size = (2, 2), strides = 2, padding = 'same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same',\n",
        "                 kernel_regularizer = l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same',\n",
        "                 kernel_regularizer = l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size = (2, 2), strides = 2, padding = 'same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, kernel_regularizer = l2(0.001)))))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaOgiVjSTtH7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBLxlOgYTuzm"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = Adam(1e-4),\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['acc']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DDtuzsSTwTy"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs = 100,\n",
        "    batch_size = 32,\n",
        "    validation_data = (X_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OocAwYZXYos"
      },
      "source": [
        "# 6. 그래프\n",
        "- '훈련, 검증 손실 그래프', '훈련, 검증 정확도 그래프'\n",
        "- 규제화 함수 사용 : 기본 설정에 비해서 훈련, 검증 그래프의 벌어짐이 약간 개선됨, 성능은 비슷함\n",
        "- 드롭 아웃 사용 : 훈련, 검증 그래프의 벌어짐이 크게 개선됨, 성능은 약간 낮아짐\n",
        "- 배치 정규화 사용 : 훈련, 검증 그래프의 벌어짐이 더 심해짐, 성능은 크게 향상됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGXsF3WrXUWH"
      },
      "outputs": [],
      "source": [
        "his_dict = history.history\n",
        "loss = his_dict['loss']\n",
        "val_loss = his_dict['val_loss'] \n",
        "epochs = range(1, len(loss) + 1)\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "# 훈련, 검증 손실\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(epochs, loss, color = 'blue', label = 'train_loss')\n",
        "ax1.plot(epochs, val_loss, color = 'orange', label = 'val_loss')\n",
        "ax1.set_title('train and val loss')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.legend()\n",
        "acc = his_dict['acc']\n",
        "val_acc = his_dict['val_acc']\n",
        "# 훈련, 검증 정확도\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(epochs, acc, color = 'blue', label = 'train_acc')\n",
        "ax2.plot(epochs, val_acc, color = 'orange', label = 'val_acc')\n",
        "ax2.set_title('train and val acc')\n",
        "ax2.set_xlabel('epochs')\n",
        "ax2.set_ylabel('acc')\n",
        "ax2.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8nMDTcuZMsP"
      },
      "source": [
        "# 7. H5 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhoBLlNzZPqW"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model.save('pepper.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "07_CNN_all_서동규.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
